{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, regexp_extract, when, lit, avg\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Spark ML on titanic data \")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./titanic_full.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = spark.read.csv(path,header = 'True',inferSchema='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic information about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|             Parch|            Ticket|              Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "|  count|             1309|               1309|              1309|                1309|  1309|              1046|              1309|              1309|              1309|              1308|  295|    1307|\n",
      "|   mean|            655.0|0.37738731856378915| 2.294881588999236|                null|  null|29.881137667304014|0.4988540870893812|0.3850267379679144| 249039.1368861024|  33.2954792813456| null|    null|\n",
      "| stddev|378.0200611960517|0.48491831071362734|0.8378360189701276|                null|  null|14.413493211271321|1.0416583905961028|0.8655602753495157|442685.31767656445|51.758668239174135| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.17|                 0|                 0|            110152|               0.0|  A10|       C|\n",
      "|    max|             1309|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                 9|         WE/P 5735|          512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "\n",
      "total number of passengers in train set is: 1309\n"
     ]
    }
   ],
   "source": [
    "#See data\n",
    "display(titanic_df)\n",
    "titanic_df.printSchema()\n",
    "titanic_df.describe().show()\n",
    "#count passenger \n",
    "passengers_count = titanic_df.count()\n",
    "print(\"total number of passengers in train set is: \"+ str(passengers_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  494|\n",
      "|       0|  815|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count survived and dead\n",
    "titanic_df.groupBy(\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 891 passengers in dataset, only about 342 survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|   Sex|Survived|count|\n",
      "+------+--------+-----+\n",
      "|  male|       0|  734|\n",
      "|female|       1|  385|\n",
      "|female|       0|   81|\n",
      "|  male|       1|  109|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Surival rate by gender\n",
    "titanic_df.groupBy(\"Sex\",\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the number of males are more than females on ship, the female survivors are twice the number of males saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|Pclass|Survived|count|\n",
      "+------+--------+-----+\n",
      "|     1|       0|  137|\n",
      "|     3|       1|  191|\n",
      "|     1|       1|  186|\n",
      "|     2|       1|  117|\n",
      "|     2|       0|  160|\n",
      "|     3|       0|  518|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Surival rate by passenger class\n",
    "titanic_df.groupBy(\"Pclass\",\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that Passenegers Of Pclass 1 were given a very high priority while rescue. Even though the the number of Passengers in Pclass 3 were a lot higher, still the number of survival from them is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function use to print feature with null values and null count \n",
    "def null_value_count(df):\n",
    "  null_columns_counts = []\n",
    "  numRows = df.count()\n",
    "  for k in df.columns:\n",
    "    nullRows = df.where(col(k).isNull()).count()\n",
    "    if(nullRows > 0):\n",
    "      temp = k,nullRows\n",
    "      null_columns_counts.append(temp)\n",
    "  return(null_columns_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling function\n",
    "null_columns_count_list = null_value_count(titanic_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                   Age|              263|\n",
      "|                  Fare|                1|\n",
      "|                 Cabin|             1014|\n",
      "|              Embarked|                2|\n",
      "+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.881137667304014\n"
     ]
    }
   ],
   "source": [
    "mean_age = titanic_df.select(mean('Age')).collect()[0][0]\n",
    "print(mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Braund, Mr. Owen ...|\n",
      "|Cumings, Mrs. Joh...|\n",
      "|Heikkinen, Miss. ...|\n",
      "|Futrelle, Mrs. Ja...|\n",
      "|Allen, Mr. Willia...|\n",
      "|    Moran, Mr. James|\n",
      "|McCarthy, Mr. Tim...|\n",
      "|Palsson, Master. ...|\n",
      "|Johnson, Mrs. Osc...|\n",
      "|Nasser, Mrs. Nich...|\n",
      "|Sandstrom, Miss. ...|\n",
      "|Bonnell, Miss. El...|\n",
      "|Saundercock, Mr. ...|\n",
      "|Andersson, Mr. An...|\n",
      "|Vestrom, Miss. Hu...|\n",
      "|Hewlett, Mrs. (Ma...|\n",
      "|Rice, Master. Eugene|\n",
      "|Williams, Mr. Cha...|\n",
      "|Vander Planke, Mr...|\n",
      "|Masselmani, Mrs. ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replace these NaN values, we can assign them the mean age of the dataset.But the problem is, there were many people with many different ages. We just cant assign a 4 year kid with the mean age that is 29 years.\n",
    "we can check the Name feature. Looking upon the feature, we can see that the names have a salutation like Mr or Mrs. Thus we can assign the mean values of Mr and Mrs to the respective groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "| Initial|\n",
      "+--------+\n",
      "|    Dona|\n",
      "|     Don|\n",
      "|    Miss|\n",
      "|Countess|\n",
      "|     Col|\n",
      "|     Rev|\n",
      "|    Lady|\n",
      "|  Master|\n",
      "|     Mme|\n",
      "|    Capt|\n",
      "|      Mr|\n",
      "|      Dr|\n",
      "|     Mrs|\n",
      "|     Sir|\n",
      "|Jonkheer|\n",
      "|    Mlle|\n",
      "|   Major|\n",
      "|      Ms|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "#Check the new \"initial\" column with unique values\n",
    "titanic_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Regex \"\"[A-Za-z]+).\" we extract the initials from the Name. It looks for strings which lie between A-Z or a-z and followed by a .(dot).\n",
    "There are some misspelled Initials like Mlle or Mme that stand for Miss. I will replace them with Miss and same thing for other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize initial\n",
    "titanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|   Dona|\n",
      "|   Miss|\n",
      "|  Other|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|    Mrs|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Initial='Dona', avg(Age)=39.0),\n",
       " Row(Initial='Miss', avg(Age)=21.834532710280374),\n",
       " Row(Initial='Other', avg(Age)=44.92307692307692),\n",
       " Row(Initial='Master', avg(Age)=5.482641509433963),\n",
       " Row(Initial='Mr', avg(Age)=32.545531197301855),\n",
       " Row(Initial='Mrs', avg(Age)=37.03488372093023)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby('Initial').avg('Age').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " impute missing values in age feature based on average age of Initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Miss\") & (titanic_df[\"Age\"].isNull()), 22).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Other\") & (titanic_df[\"Age\"].isNull()), 46).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Master\") & (titanic_df[\"Age\"].isNull()), 5).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mr\") & (titanic_df[\"Age\"].isNull()), 33).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mrs\") & (titanic_df[\"Age\"].isNull()), 36).otherwise(titanic_df[\"Age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "+-------+\n",
      "\n",
      "+----+\n",
      "| Age|\n",
      "+----+\n",
      "|22.0|\n",
      "|38.0|\n",
      "|26.0|\n",
      "|35.0|\n",
      "|35.0|\n",
      "|33.0|\n",
      "|54.0|\n",
      "| 2.0|\n",
      "|27.0|\n",
      "|14.0|\n",
      "| 4.0|\n",
      "|58.0|\n",
      "|20.0|\n",
      "|39.0|\n",
      "|14.0|\n",
      "|55.0|\n",
      "| 2.0|\n",
      "|33.0|\n",
      "|31.0|\n",
      "|36.0|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.filter(titanic_df.Age==46).select(\"Initial\").show()\n",
    "titanic_df.select(\"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                  Fare|                1|\n",
      "|                 Cabin|             1014|\n",
      "|              Embarked|                2|\n",
      "+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check remaining NAs\n",
    "null_columns_count_list = null_value_count(titanic_df)\n",
    "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All NAs in ages is treat. \n",
    "Let's treat 2 NAs in Embarked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|  123|\n",
      "|    null|    2|\n",
      "|       C|  270|\n",
      "|       S|  914|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Embarked\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the mode is 'S', we can replace port of embarkment for missing values as S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.na.fill({\"Embarked\" : 'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                  Fare|                1|\n",
      "|                 Cabin|             1014|\n",
      "+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check remaining NAs\n",
    "null_columns_count_list = null_value_count(titanic_df)\n",
    "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one missing value in fare, we can replace this with mean of fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|       avg(Fare)|\n",
      "+----------------+\n",
      "|33.2954792813456|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.agg(avg(col(\"Fare\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.na.fill({\"Fare\" : 33.29})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin has more than 10% of NA, we will drop this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = false)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- Initial: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Family_Size And Alone columns to understand the effect of family on survival rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new feature called \"Family_size\" and \"Alone\" and analyse it. This feature is the summation of Parch(parents/children) and SibSp(siblings/spouses). It gives us a combined data so that we can check if survival rate have anything to do with family size of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Family_Size|count|\n",
      "+-----------+-----+\n",
      "|          1|  235|\n",
      "|          6|   16|\n",
      "|          3|   43|\n",
      "|          5|   25|\n",
      "|          4|   22|\n",
      "|          7|    8|\n",
      "|         10|   11|\n",
      "|          2|  159|\n",
      "|          0|  790|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titanic_df.groupBy(\"Family_Size\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new column named \"alone\"\n",
    "titanic_df = titanic_df.withColumn('Alone',lit(0))\n",
    "#if that person is alone, marked as 1\n",
    "titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Embarked',\n",
       " 'Initial',\n",
       " 'Family_Size',\n",
       " 'Alone']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Sex, Embarked & Initial columns from string to number using StringIndexer for machine learning purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(titanic_df) for column in [\"Sex\",\"Embarked\",\"Initial\"]]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "titanic_df = pipeline.fit(titanic_df).transform(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Initial</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Sex_index</th>\n",
       "      <th>Embarked_index</th>\n",
       "      <th>Initial_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Embarked Initial  Family_Size  Alone  \\\n",
       "0      0         A/5 21171   7.2500        S      Mr            1      0   \n",
       "1      0          PC 17599  71.2833        C     Mrs            1      0   \n",
       "2      0  STON/O2. 3101282   7.9250        S    Miss            0      1   \n",
       "3      0            113803  53.1000        S     Mrs            1      0   \n",
       "4      0            373450   8.0500        S      Mr            0      1   \n",
       "\n",
       "   Sex_index  Embarked_index  Initial_index  \n",
       "0        0.0             0.0            0.0  \n",
       "1        1.0             1.0            2.0  \n",
       "2        1.0             0.0            1.0  \n",
       "3        1.0             0.0            2.0  \n",
       "4        0.0             0.0            0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are unnecessary for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\",\"Initial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Sex_index</th>\n",
       "      <th>Embarked_index</th>\n",
       "      <th>Initial_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Family_Size  Alone  \\\n",
       "0         0       3  22.0      1      0   7.2500            1      0   \n",
       "1         1       1  38.0      1      0  71.2833            1      0   \n",
       "2         1       3  26.0      0      0   7.9250            0      1   \n",
       "3         1       1  35.0      1      0  53.1000            1      0   \n",
       "4         0       3  35.0      0      0   8.0500            0      1   \n",
       "\n",
       "   Sex_index  Embarked_index  Initial_index  \n",
       "0        0.0             0.0            0.0  \n",
       "1        1.0             1.0            2.0  \n",
       "2        1.0             0.0            1.0  \n",
       "3        1.0             0.0            2.0  \n",
       "4        0.0             0.0            0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put all features into vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(inputCols=titanic_df.columns[1:],outputCol=\"features\")\n",
    "feature_vector= feature.transform(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Sex_index</th>\n",
       "      <th>Embarked_index</th>\n",
       "      <th>Initial_index</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(3.0, 22.0, 1.0, 0.0, 7.25, 1.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1.0, 38.0, 1.0, 0.0, 71.2833, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3.0, 26.0, 0.0, 0.0, 7.925, 0.0, 1.0, 1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1.0, 35.0, 1.0, 0.0, 53.1, 1.0, 0.0, 1.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(3.0, 35.0, 0.0, 0.0, 8.05, 0.0, 1.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Family_Size  Alone  \\\n",
       "0         0       3  22.0      1      0   7.2500            1      0   \n",
       "1         1       1  38.0      1      0  71.2833            1      0   \n",
       "2         1       3  26.0      0      0   7.9250            0      1   \n",
       "3         1       1  35.0      1      0  53.1000            1      0   \n",
       "4         0       3  35.0      0      0   8.0500            0      1   \n",
       "\n",
       "   Sex_index  Embarked_index  Initial_index  \\\n",
       "0        0.0             0.0            0.0   \n",
       "1        1.0             1.0            2.0   \n",
       "2        1.0             0.0            1.0   \n",
       "3        1.0             0.0            2.0   \n",
       "4        0.0             0.0            0.0   \n",
       "\n",
       "                                            features  \n",
       "0  (3.0, 22.0, 1.0, 0.0, 7.25, 1.0, 0.0, 0.0, 0.0...  \n",
       "1  [1.0, 38.0, 1.0, 0.0, 71.2833, 1.0, 0.0, 1.0, ...  \n",
       "2  [3.0, 26.0, 0.0, 0.0, 7.925, 0.0, 1.0, 1.0, 0....  \n",
       "3  [1.0, 35.0, 1.0, 0.0, 53.1, 1.0, 0.0, 1.0, 0.0...  \n",
       "4  (3.0, 35.0, 0.0, 0.0, 8.05, 0.0, 1.0, 0.0, 0.0...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "#Training algo\n",
    "lrModel = lr.fit(trainingData)\n",
    "lr_prediction = lrModel.transform(testData)\n",
    "lr_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.936211621642326,-0.03742945403867884,-0.31160435916009854,-0.18607357710826647,0.002830435680720263,-0.19000330359121198,-0.5376754482877728,3.28952480250676,0.20019681955416727,0.45366867352908014]\n",
      "Intercept: 1.5298824346365505\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating accuracy of LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[147  12]\n",
      " [ 22  64]]\n",
      "Accuracy of LogisticRegression is = 0.861224\n",
      "Test Error of LogisticRegression = 0.138776 \n",
      "F-score of LogisticRegression is = 0.859057\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = lr_prediction.select(\"Survived\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = lr_prediction.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#Accuracy, precision\n",
    "evaluator1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", \\\n",
    "                                               metricName = \"accuracy\")\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "lr_accuracy = evaluator1.evaluate(lr_prediction)\n",
    "lr_fscore = evaluator2.evaluate(lr_prediction)\n",
    "\n",
    "print(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\n",
    "print(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))\n",
    "print(\"F-score of LogisticRegression is = %g\"% (lr_fscore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(trainingData)\n",
    "dt_prediction = dt_model.transform(testData)\n",
    "dt_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating accuracy of DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[144  15]\n",
      " [ 23  63]]\n",
      "Accuracy of DecisionTree is = 0.861224\n",
      "Test Error of DecisionTree = 0.138776 \n",
      "F-score of DecisionTree is = 0.859057\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = dt_prediction.select(\"Survived\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = dt_prediction.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#Accuracy, precision\n",
    "evaluator1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", \\\n",
    "                                               metricName = \"accuracy\")\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "dt_accuracy = evaluator1.evaluate(lr_prediction)\n",
    "dt_fscore = evaluator2.evaluate(lr_prediction)\n",
    "\n",
    "print(\"Accuracy of DecisionTree is = %g\"% (dt_accuracy))\n",
    "print(\"Test Error of DecisionTree = %g \" % (1.0 - dt_accuracy))\n",
    "print(\"F-score of DecisionTree is = %g\"% (dt_fscore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
      "|       0.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|[1.0,53.0,0.0,0.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "rf_model = rf.fit(trainingData)\n",
    "rf_prediction = rf_model.transform(testData)\n",
    "rf_prediction.select(\"prediction\", \"Survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating accuracy of RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[149  10]\n",
      " [ 22  64]]\n",
      "Accuracy of RandomForest is = 0.869388\n",
      "Test Error of RandomForest = 0.130612 \n",
      "F-score of RandomForest is = 0.866865\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = rf_prediction.select(\"Survived\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = rf_prediction.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#Accuracy, precision\n",
    "evaluator1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", \\\n",
    "                                               metricName = \"accuracy\")\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "rf_accuracy = evaluator1.evaluate(rf_prediction)\n",
    "rf_fscore = evaluator2.evaluate(rf_prediction)\n",
    "\n",
    "print(\"Accuracy of RandomForest is = %g\"% (rf_accuracy))\n",
    "print(\"Test Error of RandomForest = %g \" % (1.0 - rf_accuracy))\n",
    "print(\"F-score of RandomForest is = %g\"% (rf_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
      "|       0.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|[1.0,53.0,0.0,0.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\",maxIter=10)\n",
    "gbt_model = gbt.fit(trainingData)\n",
    "gbt_prediction = gbt_model.transform(testData)\n",
    "gbt_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy of Gradient-boosted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[145  14]\n",
      " [ 22  64]]\n",
      "Accuracy of  Gradient-boosted DecisionTree is = 0.853061\n",
      "Test Error of  Gradient-boosted DecisionTree = 0.146939 \n",
      "F-score of  Gradient-boosted DecisionTree is = 0.85128\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = gbt_prediction.select(\"Survived\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = gbt_prediction.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#Accuracy, precision\n",
    "evaluator1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", \\\n",
    "                                               metricName = \"accuracy\")\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "gbt_accuracy = evaluator1.evaluate(gbt_prediction)\n",
    "gbt_fscore = evaluator2.evaluate(gbt_prediction)\n",
    "\n",
    "print(\"Accuracy of  Gradient-boosted DecisionTree is = %g\"% (gbt_accuracy))\n",
    "print(\"Test Error of  Gradient-boosted DecisionTree = %g \" % (1.0 - gbt_accuracy))\n",
    "print(\"F-score of  Gradient-boosted DecisionTree is = %g\"% (gbt_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       1.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       1.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       1.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "nb_model = nb.fit(trainingData)\n",
    "nb_prediction = nb_model.transform(testData)\n",
    "nb_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating accuracy of NaiveBayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[132  27]\n",
      " [ 49  37]]\n",
      "Accuracy of NaiveBayes is = 0.689796\n",
      "Test Error of NaiveBayes = 0.310204 \n",
      "F-score of NaiveBayes is = 0.677084\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = nb_prediction.select(\"Survived\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = nb_prediction.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#Accuracy, precision\n",
    "evaluator1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", \\\n",
    "                                               metricName = \"accuracy\")\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "nb_accuracy = evaluator1.evaluate(nb_prediction)\n",
    "nb_fscore = evaluator2.evaluate(nb_prediction)\n",
    "\n",
    "print(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))\n",
    "print(\"Test Error of NaiveBayes = %g \" % (1.0 - nb_accuracy))\n",
    "print(\"F-score of NaiveBayes is = %g\"% (nb_fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "svm = LinearSVC(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "svm_model = svm.fit(trainingData)\n",
    "svm_prediction = svm_model.transform(testData)\n",
    "svm_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the accuracy of Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[146  13]\n",
      " [ 23  63]]\n",
      "Accuracy of SupportVectorMachine is = 0.853061\n",
      "Test Error of SupportVectorMachine = 0.146939 \n",
      "F-score of SupportVectorMachine is = 0.850766\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = svm_prediction.select(\"Survived\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = svm_prediction.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "#Accuracy, precision\n",
    "evaluator1 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", \\\n",
    "                                               metricName = \"accuracy\")\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "svm_accuracy = evaluator1.evaluate(svm_prediction)\n",
    "svm_fscore = evaluator2.evaluate(svm_prediction)\n",
    "\n",
    "print(\"Accuracy of SupportVectorMachine is = %g\"% (svm_accuracy))\n",
    "print(\"Test Error of SupportVectorMachine = %g \" % (1.0 - svm_accuracy))\n",
    "print(\"F-score of SupportVectorMachine is = %g\"% (svm_fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
